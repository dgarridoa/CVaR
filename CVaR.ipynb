{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Value at Risk (CVaR) in Multiproduct Newsvendor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Stochastic Optimization\n",
    "\n",
    "Sea $\\xi$ un vector aleatorio con medida de probabilidad $\\mathbb{P}$, y soporte $\\Omega \\subset \\mathbb{R}^{d}$ y sean $\\{\\xi^{i}\\}_{i=1}^{N}$ iid samples de $\\xi$ talque $\\mathbb{P}_{N}(\\xi=\\xi^{i})=\\frac{1}{N}$.\n",
    "\n",
    "## 1.1 Problema original:\n",
    "\n",
    "\\begin{align}\n",
    "(P) \\;\n",
    "\\underset{x \\in X}{\\text{minimize}}& \\; f(x) = \\mathbb{E}[F(x, \\xi)]\\nonumber\n",
    "\\end{align}\n",
    "\n",
    "$F(x, \\xi)$ es la solución de otro problema de optimización, si los parámetros con componente estocástico tuvieran una distribución discreta $\\mathbb{E}[F(x, \\xi)]$ tiene una formula cerrada a través de una sumatoria, sino se tiene $\\mathbb{E}[F(x, \\xi)]$ no se puede computar ya que la integral de la esperanza se vuelve intratable computacionalmente y por tanto se debe apróximar a través de monte carlo, es decir, a través de sampling.\n",
    "\n",
    "## 1.2. Problema aproximado:\n",
    "\n",
    "\\begin{align}\n",
    "(\\hat{P}_{N}) \\;\n",
    "\\underset{x \\in X}{\\text{minimize}}& \\; \\hat{f}_{N}(x) = \\mathbb{E}_{P_{N}}[F(x, \\xi)]=\\frac{1}{N}\\sum_{i=1}^{N}F(x, \\xi^{i})\\nonumber\n",
    "\\end{align}\n",
    "\n",
    "Sea $\\delta$ el valor óptimo del promeblema original y $S$ el conjunto de soluciones óptimas, por otro lado $\\hat{\\delta}_{N}$ y $\\hat{S}_{N}$ el valor óptimo y el conjunto de soluciones óptimas del problema aproximado respectivamente.\n",
    "\n",
    "## 1.3. Cotas\n",
    "\n",
    "Se tienen dos cotas para el valor objetivo del problema original:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\forall N \\in \\mathbb{N}, \\; \\mathbb{E}[\\hat{\\delta}_{N}]\\leq\\delta\\leq\\mathbb{E}[F(x,\\xi)], \\; \\forall x \\in X\n",
    "\\end{equation*}\n",
    "\n",
    "¿Cómo estimamos las cotas?\n",
    "\n",
    "### 1.3.1 Cota inferior\n",
    "\n",
    "Fijar $N$ y resolver $n_{1}$ problemas con $n_{1}<N$, luego obtenemos el conjunto de valores óptimos $\\{ \\hat{\\delta}_{N,i} \\}_{i=1}^{n_{1}}$ y $\\{ \\hat{x}_{N,i} \\}_{i=1}^{n_{1}}$soluciones óptimos del problema aproximado. Sea $\\bar{\\delta}_{N, n_{1}}=\\frac{1}{n_{1}}\\sum_{i=1}^{n_{1}}\\hat{\\delta}_{N,i}$ el promedio de la cota inferior y $s_{N, n_{1}}^{2}=\\frac{1}{n_{1}(n_{1}-1)}\\sum_{i=1}^{n_{1}}(\\hat{\\delta}_{N,i}-\\bar{\\delta}_{N, n_{1}})^{2}$ la desviación estándar de la cota inferior. Por teorema central del límite se tiene:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbb{P}(LB=\\bar{\\delta}_{N, n_{1}}-z_{\\alpha}s_{N, n_{1}}\\leq \\delta)\\geq 1-\\alpha\n",
    "\\end{equation*}\n",
    "\n",
    "Donde $z_{\\alpha}$ es el valor que asociado a una distribución normal estándar\n",
    "con una probabilidad acumulada $1-\\alpha$, es decir, $\\Phi^{-1}(1-\\alpha)=z_{\\alpha}$. Notar que si $\\alpha$ es pequeño $z_{\\alpha}$ crece y por ende la cota inferior de la probabilidad es mayor.\n",
    "\n",
    "### 1.3.2 Cota superior\n",
    "\n",
    "Escoger $n_{2}$, sea $\\hat{f}_{n_{2}}(x) = \\frac{1}{n_{2}}\\sum_{j=1}^{n_{2}}F(x, \\xi^{j})$ y $s_{n_{2}}^{2}(x)=\\frac{1}{n_{2}(n_{2}-1)}\\sum_{j=1}^{n_{2}}(F(x, \\xi^{j})-\\hat{f}_{n_{2}})^{2}$ el promedio y la desviación estándar de las cotas superiores dado un $x$. Por teorema central del límite se tiene:\n",
    "    \n",
    "\\begin{equation*}\n",
    "\\mathbb{P}(\\hat{f}_{n_{2}}(x)+z_{\\alpha}s_{n_{2}}(x)\\geq \\delta)\\geq 1- \\alpha, \\; \\forall x \\in X\n",
    "\\end{equation*}\n",
    "    \n",
    "Sea $\\mu_{i} = \\hat{f}_{n_{2}}(\\hat{x}_{N,i})+z_{\\alpha}s_{n_{2}}(\\hat{x}_{N,i})$ se tiene que:\n",
    "    \n",
    "    \n",
    "\\begin{align}\n",
    "\\mathbb{P}\\big( \\;\n",
    "UB=\\underset{i =1, \\ldots n_{1}}{\\text{min}}& \\mu_{i} \\geq \\delta\\big)\\geq 1- \\alpha \\nonumber\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Formulación Newsvendor multiproducto\n",
    "\n",
    "\n",
    "## 2.1 CVaR como objetivo\n",
    "### 2.1.1 Formulación original\n",
    "\n",
    "Formulación que minimiza el $CVaR_{\\alpha}$ de las pérdidas para un newsvendor multiproducto con restricciones de capacidad en volumen y en peso:\n",
    "\n",
    "\\begin{align}\n",
    "\\underset{t, x, y}{\\text{min}}& \\;  t + \\frac{1}{1-\\alpha}\\mathbb{E}(|\\hat{z}-t|_{+})\\\\\\nonumber \n",
    "\\textrm{s.t.}\\qquad & \\; \\hat{z}=\\sum_{p \\in P}\\hat{c}_{x_{p}}x_{p}-\\hat{c}_{y_{p}}\\hat{y}_{p}\\\\\\nonumber\n",
    "& \\;\\hat{y}_{p} \\leq \\hat{d}_{p} \\qquad\\qquad\\qquad\\; \\forall p \\in P\\\\\\nonumber\n",
    "& \\;\\hat{y}_{p} \\leq x_{p} \\qquad\\qquad\\qquad\\; \\forall p \\in P\\\\\\nonumber\n",
    "& \\;\\sum_{p \\in P}\\hat{w}_{p}x_{p}\\leq W\\\\\\nonumber\n",
    "& \\;\\sum_{p \\in P}\\hat{v}_{p}x_{p}\\leq V\\\\\\nonumber\n",
    "& \\;\\hat{y}_{p} \\geq 0 \\qquad\\qquad\\qquad\\;\\;  \\forall p \\in P\\nonumber\n",
    "\\end{align}\n",
    "\n",
    "La formulación anterior se puede simplificar utilizando una variable auxiliar:\n",
    "\n",
    "\\begin{align}\n",
    "\\underset{t, x, \\hat{y}, \\hat{\\mu}}{\\text{min}}& \\;  t + \\frac{1}{1-\\alpha}\\mathbb{E}(\\hat{\\mu})\\\\ \\nonumber\n",
    "\\textrm{s.t.}\\qquad & \\; \\hat{\\mu}\\geq\\sum_{p \\in P}\\hat{c}_{x_{p}}x_{p}-\\hat{c}_{y_{p}}\\hat{y}_{p}-t\\\\\\nonumber\n",
    "& \\;\\hat{y}_{p} \\leq \\hat{d}_{p} \\qquad\\qquad\\qquad\\;\\; \\forall p \\in P\\\\\\nonumber\n",
    "& \\;\\hat{y}_{p} \\leq x_{p} \\qquad\\qquad\\qquad\\;\\; \\forall p \\in P\\\\\\nonumber\n",
    "& \\;\\sum_{p \\in P}\\hat{w}_{p}x_{p}\\leq W\\\\\\nonumber\n",
    "& \\;\\sum_{p \\in P}\\hat{v}_{p}x_{p}\\leq V\\\\\\nonumber\n",
    "& \\;\\hat{y}_{p} \\geq 0 \\qquad\\qquad\\qquad\\;\\;\\;  \\forall p \\in P\\\\\\nonumber\n",
    "& \\;\\hat{\\mu} \\geq 0 \\nonumber\n",
    "\\end{align}\n",
    "\n",
    "### 2.1.2 SAA\n",
    "\n",
    "Manipulando la función objetivo del problema anterior nos queda una esperanza $\\mathbb{E}(t + \\frac{1}{1-\\alpha}\\hat{\\mu})$. La formulación anterior no es integrable, por tanto se aproximará a través de Sampling Average Approximation (SAA):\n",
    "\n",
    "\\begin{align}\n",
    "\\underset{t, x, y, \\mu}{\\text{min}}& \\;  t + \\frac{1}{1-\\alpha}\\frac{1}{M}\\sum_{i \\in M}\\mu^{i}\\\\\\nonumber\n",
    "\\textrm{s.t.}\\qquad & \\; \\mu^{i}\\geq\\sum_{p \\in P}c^{i}_{x_{p}}x_{p}-c^{i}_{y_{p}}y^{i}_{p}-t \\qquad\\; \\forall i \\in M\\\\\\nonumber\n",
    "& \\;y^{i}_{p} \\leq d^{i}_{p} \\qquad\\qquad\\qquad\\qquad\\;\\;\\;   \\forall i \\in M\\; \\forall p \\in P\\\\\\nonumber\n",
    "& \\;y^{i}_{p} \\leq x_{p} \\qquad\\qquad\\qquad\\qquad\\;\\;\\;   \\forall i \\in M \\; \\forall p \\in P\\\\\\nonumber\n",
    "& \\;\\sum_{p \\in P}w^{i}_{p}x_{p}\\leq W \\qquad\\qquad\\qquad \\forall i \\in M\\\\\\nonumber\n",
    "& \\;\\sum_{p \\in P}v^{i}_{p}x_{p}\\leq V \\qquad\\qquad\\qquad\\;\\; \\forall i \\in M\\\\\\nonumber\n",
    "& \\;y^{i}_{p} \\geq 0 \\qquad\\qquad\\qquad\\qquad\\;\\;\\;\\;  \\forall i \\in M \\; \\forall p \\in P \\\\\\nonumber\n",
    "& \\;\\mu^{i} \\geq 0 \\qquad\\qquad\\qquad\\qquad\\;\\;\\;\\;   \\forall i \\in M\\nonumber\n",
    "\\end{align}\n",
    "\n",
    "### 2.1.3 SSP\n",
    "\n",
    "El second stage problem consiste en resolver el siguiente LP dado $t$ y $x$:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "F(t,x, i) = \\underset{y^{i}}{\\text{min}}& \\; t+\\frac{1}{1-\\alpha}|\\sum_{p \\in P}c^{i}_{x_{p}}x_{p}-c^{i}_{y_{p}}y^{i}_{p}-t|_{+}\\\\ \\nonumber\n",
    "\\textrm{s.t.}\n",
    "& \\;y^{i}_{p} \\leq d^{i}_{p} \\qquad\\qquad\\qquad\\qquad\\;\\;\\; \\forall p \\in P\\\\\\nonumber\n",
    "& \\;y^{i}_{p} \\leq x_{p} \\qquad\\qquad\\qquad\\qquad\\;\\;\\; \\forall p \\in P\\\\\\nonumber\n",
    "& \\;y^{i}_{p} \\geq 0 \\qquad\\qquad\\qquad\\qquad\\;\\;\\;\\; \\forall p \\in P \\\\\\nonumber\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Se debe tener en cuenta que $x$ debe ser tal que :\n",
    "\n",
    "\\begin{align}\n",
    "&\\sum_{p \\in P}w_{p}x_{p}\\leq W \\\\\\nonumber\n",
    "&\\sum_{p \\in P}v_{p}x_{p}\\leq V \\\\\\nonumber\n",
    "\\end{align}\n",
    "\n",
    "El problema anterior tiene solución trivial y esta es cuando $y^{i}_{p}=min\\{d^{i}_{p},x_{p}\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 CVaR como restricción\n",
    "\n",
    "### 2.2.1 Formulación original\n",
    "\n",
    "Formulación que minimiza las pérdidas para un newsvendor multiproducto con restricciones de capacidad en volumen y en peso y con restricción de $CVaR_{\\alpha}$:\n",
    "\n",
    "\\begin{align}\n",
    "\\underset{t, x, y}{\\text{min}}& \\; \\mathbb{E}(\\hat{z})\\\\\\nonumber \n",
    "\\textrm{s.t.}\\qquad & \\; \\hat{z}=\\sum_{p \\in P}\\hat{c}_{x_{p}}x_{p}-\\hat{c}_{y_{p}}\\hat{y}_{p}\\\\\\nonumber\n",
    "& CVaR(\\hat{z})\\leq z_{\\alpha}+0.1max\\{|z_{\\alpha}|,1\\}\\\\\\nonumber\n",
    "& \\;\\hat{y}_{p} \\leq \\hat{d}_{p} \\qquad\\qquad\\qquad\\; \\forall p \\in P\\\\\\nonumber\n",
    "& \\;\\hat{y}_{p} \\leq x_{p} \\qquad\\qquad\\qquad\\; \\forall p \\in P\\\\\\nonumber\n",
    "& \\;\\sum_{p \\in P}\\hat{w}_{p}x_{p}\\leq W\\\\\\nonumber\n",
    "& \\;\\sum_{p \\in P}\\hat{v}_{p}x_{p}\\leq V\\\\\\nonumber\n",
    "& \\;\\hat{y}_{p} \\geq 0 \\qquad\\qquad\\qquad\\;\\;  \\forall p \\in P\\nonumber\n",
    "\\end{align}\n",
    "\n",
    "La formulación anterior se puede simplificar utilizando una variable auxiliar:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\underset{t, x, y}{\\text{min}}& \\; \\mathbb{E}(\\sum_{p \\in P}\\hat{c}_{x_{p}}x_{p}-\\hat{c}_{y_{p}}\\hat{y}_{p})\\\\\\nonumber \n",
    "&  t + \\frac{1}{1-\\alpha}\\mathbb{E}(\\hat{\\mu})\\leq z_{\\alpha}+0.1max\\{|z_{\\alpha}|,1\\}\\\\\\nonumber\n",
    "& \\hat{\\mu}\\geq\\sum_{p \\in P}\\hat{c}_{x_{p}}x_{p}-\\hat{c}_{y_{p}}\\hat{y}_{p}-t\\\\\\nonumber\n",
    "& \\;\\hat{y}_{p} \\leq \\hat{d}_{p} \\qquad\\qquad\\qquad\\; \\forall p \\in P\\\\\\nonumber\n",
    "& \\;\\hat{y}_{p} \\leq x_{p} \\qquad\\qquad\\qquad\\; \\forall p \\in P\\\\\\nonumber\n",
    "& \\;\\sum_{p \\in P}\\hat{w}_{p}x_{p}\\leq W\\\\\\nonumber\n",
    "& \\;\\sum_{p \\in P}\\hat{v}_{p}x_{p}\\leq V\\\\\\nonumber\n",
    "& \\;\\hat{y}_{p} \\geq 0 \\qquad\\qquad\\qquad\\;\\;  \\forall p \\in P\\\\\\nonumber\n",
    "& \\;\\hat{\\mu} \\geq 0 \\nonumber\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "### 2.2.2 SAA\n",
    "\n",
    "\\begin{align}\n",
    "\\underset{t, x, y, \\mu}{\\text{min}}& \\; \\frac{1}{M}\\sum_{i \\in M}\\sum_{p \\in P}c^{i}_{x_{p}}x_{p}-c^{i}_{y_{p}}y^{i}_{p}\\\\\\nonumber\n",
    "\\textrm{s.t.}\\qquad & \\;  t + \\frac{1}{1-\\alpha}\\frac{1}{M}\\sum_{i \\in M}\\mu_{i}\\leq z_{\\alpha}+0.1\\cdot max\\{|z_{\\alpha}|,1\\}\\\\\\nonumber\n",
    "& \\;\\mu^{i}\\geq\\sum_{p \\in P}c^{i}_{x_{p}}x_{p}-c^{i}_{y_{p}}y^{i}_{p}-t \\qquad\\; \\forall i \\in M\\\\\\nonumber\n",
    "& \\;y^{i}_{p} \\leq d^{i}_{p} \\qquad\\qquad\\qquad\\qquad\\;\\;\\;   \\forall i \\in M\\; \\forall p \\in P\\\\\\nonumber\n",
    "& \\;y^{i}_{p} \\leq x_{p} \\qquad\\qquad\\qquad\\qquad\\;\\;\\;   \\forall i \\in M \\; \\forall p \\in P\\\\\\nonumber\n",
    "& \\;\\sum_{p \\in P}w^{i}_{p}x_{p}\\leq W \\qquad\\qquad\\qquad \\forall i \\in M\\\\\\nonumber\n",
    "& \\;\\sum_{p \\in P}v^{i}_{p}x_{p}\\leq V \\qquad\\qquad\\qquad\\;\\; \\forall i \\in M\\\\\\nonumber\n",
    "& \\;y^{i}_{p} \\geq 0 \\qquad\\qquad\\qquad\\qquad\\;\\;\\;\\;  \\forall i \\in M \\; \\forall p \\in P \\\\\\nonumber\n",
    "& \\;\\mu^{i} \\geq 0 \\qquad\\qquad\\qquad\\qquad\\;\\;\\;\\;   \\forall i \\in M\\nonumber\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "### 2.2.4 SSP\n",
    "\n",
    "El second stage problem consiste en resolver el siguiente LP dado $t$ y $x$:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "F(t,x, i) = \\underset{y^{i}}{\\text{min}}& \\; \\sum_{p \\in P}c^{i}_{x_{p}}x_{p}-c^{i}_{y_{p}}y^{i}_{p}\\\\ \\nonumber\n",
    "& \\;y^{i}_{p} \\leq d^{i}_{p} \\qquad\\qquad\\qquad\\qquad\\;\\;\\; \\forall p \\in P\\\\\\nonumber\n",
    "& \\;y^{i}_{p} \\leq x_{p} \\qquad\\qquad\\qquad\\qquad\\;\\;\\; \\forall p \\in P\\\\\\nonumber\n",
    "& \\;y^{i}_{p} \\geq 0 \\qquad\\qquad\\qquad\\qquad\\;\\;\\;\\; \\forall p \\in P \\\\\\nonumber\n",
    "\\end{align}\n",
    "\n",
    "Se debe tener en cuenta que $x$ debe ser tal que :\n",
    "\n",
    "\\begin{align}\n",
    "&\\sum_{p \\in P}w_{p}x_{p}\\leq W \\\\\\nonumber\n",
    "&\\sum_{p \\in P}v_{p}x_{p}\\leq V \\\\\\nonumber\n",
    "\\end{align}\n",
    "\n",
    "El problema anterior tiene solución trivial y esta es cuando $y^{i}_{p}=min\\{d^{i}_{p},x_{p}\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gurobipy as grb\n",
    "from scipy.stats import norm\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_normal_sampling(mu, sigma, sample_size, seed):\n",
    "    \"\"\"\n",
    "    Draw random samples from a normal distribution, reject the negative samples\n",
    "    Parameter:\n",
    "        mu: float, int, numpy array or list\n",
    "            means of the distributions.\n",
    "        sigma: float, int, numpy array or list\n",
    "            standart deviations of the distributions.\n",
    "        sample_size: int\n",
    "            number of samples to sample.\n",
    "        seed: int\n",
    "            seed sampling.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    samples = []\n",
    "    length = 0\n",
    "    while length<sample_size:\n",
    "        if (type(mu)==float) or (type(mu)==int):\n",
    "            sample = np.random.normal(mu, sigma)\n",
    "        else:\n",
    "            sample = np.array([np.random.normal(mu[i], sigma[i]) for i in range(len(mu))]).sum()\n",
    "        if sample>=0:\n",
    "            samples.append(sample)\n",
    "            length = length+1\n",
    "    return np.array(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_lb(N1, M, P, seed):\n",
    "    \"\"\"\n",
    "    Draw data samples for computing lower bound\n",
    "    Parameters:\n",
    "        N1: int\n",
    "            insample size.\n",
    "        M: int\n",
    "            repetitions.\n",
    "        P: int\n",
    "            products.\n",
    "        seed: int\n",
    "            seed sampling.\n",
    "            \n",
    "    Output:\n",
    "        c_x: numpy array, shape(M, P, N1)\n",
    "            Products purchase prices.\n",
    "        c_y: numpy array, shape(M, P, N1)\n",
    "            Products sale prices.\n",
    "        d: numpy array, shape(M, P, N1)\n",
    "            Products demands.\n",
    "        w: numpy array, shape(M, P, N1)\n",
    "            Product weights.\n",
    "        v: numpy array, shape(M, P, N1)\n",
    "            Product volumens.\n",
    "        W: numpy array, shape(N1)\n",
    "            Weigth capacity.\n",
    "        V: numpy array, shape(N1)\n",
    "            Volumen capacity.\n",
    "    \"\"\"\n",
    "    #initializations\n",
    "    mu1 = np.zeros(P)\n",
    "    mu2 = np.zeros(P)\n",
    "    sigma1 = np.zeros(P)\n",
    "    sigma2 = np.zeros(P)\n",
    "    \n",
    "    c_x = np.zeros((M,P,N1))\n",
    "    c_y = np.zeros((M,P,N1))\n",
    "    d = np.zeros((M,P,N1))\n",
    "    w = np.zeros((M,P,N1))\n",
    "    v = np.zeros((M,P,N1))\n",
    "    \n",
    "    for p in range(P):\n",
    "         #costs\n",
    "        c_x[:,p,:] = positive_normal_sampling(mu=1, sigma=1, sample_size=M*N1, seed=seed+p).reshape(M,N1)\n",
    "        c_y[:,p,:] = positive_normal_sampling(mu=1, sigma=1, sample_size=M*N1, seed=seed+p+P).reshape(M,N1)+c_x[:,p,:]\n",
    "        #demands \n",
    "        mu1, mu2 = positive_normal_sampling(mu=2, sigma=1, sample_size=2, seed=seed+p)\n",
    "        sigma1, sigma2 = positive_normal_sampling(mu=1, sigma=2, sample_size=2, seed=seed+p)\n",
    "        d[:,p,:] = positive_normal_sampling(mu=[mu1, mu2], sigma=[sigma1, sigma2], sample_size=M*N1, seed=seed+p).reshape(M,N1)\n",
    "        #weigths and volumens  \n",
    "        w[:,p,:] = positive_normal_sampling(mu=3, sigma=1, sample_size=M*N1, seed=seed+p).reshape(M,N1)\n",
    "        v[:,p,:] = positive_normal_sampling(mu=3, sigma=1, sample_size=M*N1, seed=seed+p+P).reshape(M,N1)\n",
    "              \n",
    "    #weights and volumens capacities\n",
    "    W = V = 14*d.sum(axis=1).mean(axis=0)\n",
    "    \n",
    "    return  c_x, c_y, d, w, v, W, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_ub(N2, P, seed):\n",
    "    \"\"\"\n",
    "    Draw data samples for computing upper bound\n",
    "    Parameters:\n",
    "        N2: int\n",
    "            outsample size.\n",
    "        P: int\n",
    "            products.\n",
    "        seed: int\n",
    "            seed sampling.\n",
    "            \n",
    "    Output:\n",
    "        c_x: numpy array, shape(N2, P)\n",
    "            Products purchase prices.\n",
    "        c_y: numpy array, shape(N2, P)\n",
    "            Products sale prices.\n",
    "        d: numpy array, shape(N2, P)\n",
    "            Products demands.\n",
    "    \"\"\"\n",
    "    #initializations\n",
    "    mu1 = np.zeros(P)\n",
    "    mu2 = np.zeros(P)\n",
    "    sigma1 = np.zeros(P)\n",
    "    sigma2 = np.zeros(P)\n",
    "    \n",
    "    c_x = np.zeros((N2,P))\n",
    "    c_y = np.zeros((N2,P))\n",
    "    d = np.zeros((N2,P))\n",
    "    \n",
    "    for p in range(P):\n",
    "        #costs\n",
    "        c_x[:,p] = positive_normal_sampling(mu=1, sigma=1, sample_size=N2, seed=seed+p)\n",
    "        c_y[:,p] = positive_normal_sampling(mu=1, sigma=1, sample_size=N2, seed=seed+p+P)+c_x[:,p]\n",
    "        #demands \n",
    "        mu1, mu2 = positive_normal_sampling(mu=2, sigma=1, sample_size=2, seed=seed+p)\n",
    "        sigma1, sigma2 = positive_normal_sampling(mu=1, sigma=2, sample_size=2, seed=seed+p)\n",
    "        d[:,p] = positive_normal_sampling(mu=[mu1, mu2], sigma=[sigma1, sigma2], sample_size=N2, seed=seed+p)\n",
    "        \n",
    "    \n",
    "    return c_x, c_y, d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saa_cvar_obj(c_x, c_y, d, w, v, W, V, alpha, verbose=False):\n",
    "    \"\"\"\n",
    "    Sample Average Approximation (SAA) for newsvendor with CVar as objetive\n",
    "    Parameters:\n",
    "        c_x: numpy array, shape(repetitions, products)\n",
    "            Products purchase prices.\n",
    "        c_y: numpy array, shape(repetitions, products)\n",
    "            Products sale prices.\n",
    "        d: numpy array, shape(repetitions, products)\n",
    "            Products demands.\n",
    "        w: numpy array, shape(repetitions, products)\n",
    "            Product weights.\n",
    "        v: numpy array, shape(repetitions, products)\n",
    "            Product volumens.\n",
    "        W: int, float\n",
    "            Weigth capacity.\n",
    "        V: int, float\n",
    "            Volumen capacity.\n",
    "        alpha: float\n",
    "            alpha between ]0,1[, conditional value at risk (for losses) is the expected value \n",
    "            of the worst (1-alpha)% tail of the realizations.\n",
    "        verbose: bool\n",
    "            If is True display the logs.\n",
    "    Output:\n",
    "        model: gurobi.Model\n",
    "            Gurobi model that optimize the CVaR(alpha,losses) using sample average approximation.\n",
    "        x_opt: numpy array, shape(products)\n",
    "            Optimal quantities to order for each product.\n",
    "        t_opt: float\n",
    "            Optimal t from CVaR.\n",
    "    \"\"\"\n",
    "    #shape\n",
    "    M, P = d.shape    \n",
    "    \n",
    "    #create model\n",
    "    model = grb.Model('SAA')\n",
    "    model.setParam('OutputFlag', verbose)\n",
    "    \n",
    "    #variables\n",
    "    t = model.addVar(lb=-grb.GRB.INFINITY, name='t')\n",
    "    x = model.addVars(range(P), name='x')\n",
    "    y = model.addVars(range(M), range(P), name='y')\n",
    "    mu = model.addVars(range(M), name='mu')\n",
    "\n",
    "    #restrictions\n",
    "    model.addConstrs((mu[i] >= grb.quicksum(c_x[i,p]*x[p]-c_y[i,p]*y[i,p] for p in range(P))-t for i in range(M)), name=\"excess\") \n",
    "    model.addConstrs((y[i,p]<=d[i,p] for i in range(M) for p in range(P)), name=\"ub_demand\") \n",
    "    model.addConstrs((y[i,p]<=x[p] for i in range(M) for p in range(P)), name=\"ub_order\")\n",
    "    model.addConstrs((grb.quicksum(w[i,p]*x[p] for p in range(P))<=W for i in range(M)), name=\"w_cap\")\n",
    "    model.addConstrs((grb.quicksum(v[i,p]*x[p] for p in range(P))<=V for i in range(M)), name=\"v_cap\")\n",
    "        \n",
    "    #object function and optimize\n",
    "    model.setObjective(t+(1/((1-alpha)*M))*grb.quicksum(mu[i] for i in range(M)))\n",
    "    model.optimize()\n",
    "       \n",
    "    t_opt = model.x[0]\n",
    "    x_opt = np.array(model.x[1:P+1])\n",
    "    return model, x_opt, t_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssp_cvar_obj(c_x, c_y, d, x, t, alpha):\n",
    "    \"\"\"\n",
    "    Second Stage Problem (SSP) for newsvendor with CVar as objetive\n",
    "    \n",
    "    Parameters:\n",
    "        c_x: numpy array, shape(products)\n",
    "            Products purchase prices.\n",
    "        c_y: numpy array, shape(products)\n",
    "            Products sale prices\n",
    "        d: numpy array, shape(products)\n",
    "            Products demands.\n",
    "        x: numpy array, shape(products)\n",
    "            Optimal x from SAA.\n",
    "        t: float\n",
    "            Optimal t from SAA.\n",
    "        alpha: float\n",
    "            alpha between ]0,1[, conditional value at risk (for losses) is the expected value \n",
    "            of the worst (1-alpha)% tail of the realizations.\n",
    "    Output:\n",
    "        objVal: float\n",
    "            Optimal value of SSP\n",
    "    \"\"\"\n",
    "    P = len(d)        \n",
    "    y = np.array([min(x[p], d[p]) for p in range(P)])\n",
    "    losses = (c_x*x-c_y*y).sum()\n",
    "    objVal = t+(1/(1-alpha))*max(losses-t,0)\n",
    "\n",
    "    return objVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saa_cvar_rest(c_x, c_y, d, w, v, W, V, alpha, z_alpha, verbose=False):\n",
    "    \"\"\"\n",
    "    Sample Average Approximation (SAA) for newsvendor with CVar as objetive\n",
    "    Parameters:\n",
    "        c_x: numpy array, shape(repetitions, products)\n",
    "            Products purchase prices.\n",
    "        c_y: numpy array, shape(repetitions, products)\n",
    "            Products sale prices.\n",
    "        d: numpy array, shape(repetitions, products)\n",
    "            Products demands.\n",
    "        w: numpy array, shape(repetitions, products)\n",
    "            Product weights.\n",
    "        v: numpy array, shape(repetitions, products)\n",
    "            Product volumens.\n",
    "        W: int, float\n",
    "            Weigth capacity.\n",
    "        V: int, float\n",
    "            Volumen capacity.\n",
    "        alpha: float\n",
    "            alpha between ]0,1[, conditional value at risk (for losses) is the expected value \n",
    "            of the worst (1-alpha)% tail of the realizations.\n",
    "        z_alpha: float\n",
    "            optimal value from newsvendor with CVaR(alpha) as objetive\n",
    "        verbose: bool\n",
    "            If is True display the logs.\n",
    "    Output:\n",
    "        model: gurobi.Model\n",
    "            Gurobi model that optimize the CVaR(alpha,losses) using sample average approximation.\n",
    "        x_opt: numpy array, shape(products)\n",
    "            Optimal quantities to order for each product.\n",
    "        t_opt: float\n",
    "            Optimal t from CVaR.\n",
    "    \"\"\"\n",
    "    #shape\n",
    "    M, P = d.shape    \n",
    "    \n",
    "    #create model\n",
    "    model = grb.Model('SAA')\n",
    "    model.setParam('OutputFlag', verbose)\n",
    "    \n",
    "    #variables\n",
    "    t = model.addVar(lb=-grb.GRB.INFINITY, name='t')\n",
    "    x = model.addVars(range(P), name='x')\n",
    "    y = model.addVars(range(M), range(P), name='y')\n",
    "    mu = model.addVars(range(M), name='mu')\n",
    "\n",
    "    #restrictions\n",
    "    model.addConstr((t+(1/((1-alpha)*M))*grb.quicksum(mu[i] for i in range(M))<=z_alpha+0.1*max(abs(z_alpha),1)), name=\"CVaR\")\n",
    "    model.addConstrs((mu[i] >= grb.quicksum(c_x[i,p]*x[p]-c_y[i,p]*y[i,p] for p in range(P))-t for i in range(M)), name=\"excess\") \n",
    "    model.addConstrs((y[i,p]<=d[i,p] for i in range(M) for p in range(P)), name=\"ub_demand\") \n",
    "    model.addConstrs((y[i,p]<=x[p] for i in range(M) for p in range(P)), name=\"ub_order\")\n",
    "    model.addConstrs((grb.quicksum(w[i,p]*x[p] for p in range(P))<=W for i in range(M)), name=\"w_cap\")\n",
    "    model.addConstrs((grb.quicksum(v[i,p]*x[p] for p in range(P))<=V for i in range(M)), name=\"v_cap\")\n",
    "        \n",
    "    #object function and optimize\n",
    "    model.setObjective(grb.quicksum(c_x[i,p]*x[p]-c_y[i,p]*y[i,p] for p in range(P) for i in range(M))/M)\n",
    "    model.optimize()\n",
    "       \n",
    "    t_opt = model.x[0]\n",
    "    x_opt = np.array(model.x[1:P+1])\n",
    "    return model, x_opt, t_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssp_cvar_rest(c_x, c_y, d, x, t, alpha):\n",
    "    \"\"\"\n",
    "    Second Stage Problem (SSP) for newsvendor with CVar as objetive\n",
    "    \n",
    "    Parameters:\n",
    "        c_x: numpy array, shape(products)\n",
    "            Products purchase prices.\n",
    "        c_y: numpy array, shape(products)\n",
    "            Products sale prices\n",
    "        d: numpy array, shape(products)\n",
    "            Products demands.\n",
    "        x: numpy array, shape(products)\n",
    "            Optimal x from SAA.\n",
    "        t: float\n",
    "            Optimal t from SAA.\n",
    "        alpha: float\n",
    "            alpha between ]0,1[, conditional value at risk (for losses) is the expected value \n",
    "            of the worst (1-alpha)% tail of the realizations.\n",
    "    Output:\n",
    "        objVal: float\n",
    "            Optimal value of SSP\n",
    "    \"\"\"\n",
    "    P = len(d)        \n",
    "    y = np.array([min(x[p], d[p]) for p in range(P)])\n",
    "    objVal = (c_x*x-c_y*y).sum()\n",
    "    \n",
    "    return objVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_lb(c_x, c_y, d, w, v, W, V, alpha, level_sig, saa_type, z_alpha=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Shapes:         \n",
    "        N1: int\n",
    "            insample size.\n",
    "        N2: int\n",
    "            outsample size.\n",
    "        M: int\n",
    "            repetitions.\n",
    "        P: int\n",
    "            products.\n",
    "    Parameters:\n",
    "        c_x: numpy array, shape(M, P, N1)\n",
    "            Products purchase prices\n",
    "        c_y: numpy array, shape(M, P, N1)\n",
    "            Products sale prices\n",
    "        d: numpy array, shape(M, P, N1)\n",
    "            Products demands\n",
    "        w: numpy array, shape(M, P, N1)\n",
    "            Product weights.\n",
    "        v: numpy array, shape(M, P, N1)\n",
    "            Product volumens.\n",
    "        W: numpy array, shape(N1)\n",
    "            Weigth capacity.\n",
    "        V: numpy array, shape(N1)\n",
    "            Volumen capacity.\n",
    "        alpha: float\n",
    "            alpha between ]0,1[, conditional value at risk (for losses) is the expected value \n",
    "            of the worst (1-alpha)% tail of the realizations.\n",
    "        level_sig: float\n",
    "            level_sig between ]0,1[ level of statistical significance of the bound.\n",
    "        saa_type: str\n",
    "            type of SAA model to run, two option:{\"cvar_obj\", \"cvar_rest\"}.\n",
    "        z_alpha: float\n",
    "            optimal value from newsvendor with CVaR(alpha) as objetive, only for saa_type=\"cvar_rest\".\n",
    "        verbose: bool\n",
    "            If is True display the logs.\n",
    "    Output:\n",
    "        lb: float\n",
    "            Lower bound of optimal value of CVaR(alpha,losses) with an level of statistical significance \n",
    "            equal to level_sig (probability that the optimal_value >=LB is >=1-level_sig)\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    P = d.shape[1]\n",
    "    N1 = d.shape[2]\n",
    "    #saa N1 times, save objVal and optimal solutions\n",
    "    \n",
    "    delta = np.zeros(N1)\n",
    "    x = np.zeros((N1, P))\n",
    "    t = np.zeros(N1)\n",
    "    for i in range(N1):\n",
    "        if saa_type ==\"cvar_obj\":\n",
    "            model, x[i], t[i] = saa_cvar_obj(c_x[:,:,i], c_y[:,:,i], d[:,:,i], w[:,:,i], v[:,:,i], W[i], V[i], alpha, verbose=verbose)\n",
    "            delta[i] = model.objVal    \n",
    "        else: #\"cvar_rest\"\n",
    "            model, x[i], t[i] = saa_cvar_rest(c_x[:,:,i], c_y[:,:,i], d[:,:,i], w[:,:,i], v[:,:,i], W[i], V[i], alpha, z_alpha, verbose=verbose)\n",
    "            delta[i] = model.objVal  \n",
    "    #lower bound\n",
    "    delta_bar = delta.mean()\n",
    "    s = np.sqrt(((delta-delta_bar)**2).sum()/(N1*(N1-1)))    \n",
    "    z = norm.ppf(1-level_sig)\n",
    "    lb = delta_bar-z*s\n",
    "    \n",
    "    return lb, x, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_ub(c_x, c_y, d, x, t, alpha, level_sig, ssp_type):\n",
    "    \"\"\"\n",
    "    Shapes:         \n",
    "        N1: int\n",
    "            insample size.\n",
    "        N2: int\n",
    "            outsample size.\n",
    "        M: int\n",
    "            repetitions.\n",
    "        P: int\n",
    "            products.\n",
    "    Parameters:\n",
    "        c_x: numpy array, shape(N2, P)\n",
    "            Products purchase prices\n",
    "        c_y: numpy array, shape(N2, P)\n",
    "            Products sale prices\n",
    "        d: numpy array, shape(N2, P)\n",
    "            Products demands\n",
    "        x: numpy array, shape(N1, P)\n",
    "            N1 optimal solutions of x.\n",
    "        t: numpy array, shape(N1)\n",
    "            N1 optimal solutions of t.\n",
    "        alpha: float\n",
    "            alpha between ]0,1[, conditional value at risk (for losses) is the expected value \n",
    "            of the worst (1-alpha)% tail of the realizations\n",
    "        level_sig: float\n",
    "            level_sig between ]0,1[ level of statistical significance of the bound\n",
    "        ssp_type: str\n",
    "            type of SSP model to run, two option:{\"cvar_obj\", \"cvar_rest\"}.\n",
    "    Output:\n",
    "        ub: float\n",
    "            Upper bound of optimal value of CVaR(alpha,losses) with an level of statistical significance \n",
    "            equal to level_sig (probability that the optimal_value <=UB is >=1-level_sig)\n",
    "        \n",
    "    \"\"\"\n",
    "    N1 = len(x)\n",
    "    N2 = len(c_x)\n",
    "    u = np.zeros(N1)\n",
    "    f = np.zeros(N1)\n",
    "    z = norm.ppf(1-level_sig)\n",
    "    \n",
    "    for i in range(N1):\n",
    "        F = np.zeros(N2)\n",
    "        #SSP N2 times\n",
    "        for j in range(N2):\n",
    "            if ssp_type ==\"cvar_obj\":\n",
    "                F[j] = ssp_cvar_obj(c_x[j], c_y[j], d[j], x[i], t[i], alpha)\n",
    "            else:\n",
    "                F[j] = ssp_cvar_rest(c_x[j], c_y[j], d[j], x[i], t[i], alpha)\n",
    "        #upper bound candidate\n",
    "        f = F.mean()\n",
    "        s = np.sqrt(((F-f)**2).sum()/(N2*(N2-1)))  \n",
    "        u[i] = f+z*s\n",
    "    #upper bound\n",
    "    ub = u.min()\n",
    "    #best feasible solution\n",
    "    z_alpha = f.min()\n",
    "    return ub, z_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4.1. Minimizar CVaR\n",
    "\n",
    "Minimize CVaR $\\alpha$ (perdidas) para $\\alpha \\in$\n",
    "{0,01, 0,10, 0,25, 0,50, 0,75, 0,95}, y para dos niveles de in-sample, out-sample y repeticiones $N_{1}$ , $N_{2}$, $M$ dados, compute el intervalo de confianza del gap estocastico para el problema. Uno de los niveles debe asegurar un gap estocastico del 1 % para CVaR 0,95 y el otro un gap estocastico de 5 % para CVaR 0,95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_1(N1, N2, M, P, level_sig, seed):\n",
    "    \n",
    "\n",
    "    #samples for lower bound\n",
    "    c_x_1, c_y_1, d_1, w_1, v_1, W_1, V_1 = sampling_lb(N1, M, P, seed)\n",
    "\n",
    "    #samples for upper bound\n",
    "    c_x_2, c_y_2, d_2 = sampling_ub(N2, P, seed)\n",
    "\n",
    "    alphas = np.array([0.01, 0.10, 0.25, 0.50, 0.75, 0.95])\n",
    "    z_alphas = np.zeros(len(alphas))\n",
    "    gaps = np.zeros(len(alphas))\n",
    "    lower_bounds = np.zeros(len(alphas))\n",
    "    upper_bounds = np.zeros(len(alphas))\n",
    "    lb_times = np.zeros(len(alphas))\n",
    "    ub_times = np.zeros(len(alphas))\n",
    "\n",
    "    for i, alpha in enumerate(alphas):\n",
    "        ti_lb = time()\n",
    "        lower_bounds[i], x, t = computing_lb(c_x_1, c_y_1, d_1, w_1, v_1, W_1, V_1, alpha, level_sig, saa_type=\"cvar_obj\")\n",
    "        tf_lb = time()\n",
    "        lb_times[i] = tf_lb-ti_lb\n",
    "\n",
    "        ti_ub = time()\n",
    "        upper_bounds[i], z_alphas[i] = computing_ub(c_x_2, c_y_2, d_2, x, t, alpha, level_sig, ssp_type=\"cvar_obj\")\n",
    "        tf_ub = time()\n",
    "        ub_times[i] = tf_ub-ti_ub \n",
    "        gaps[i] = 100*abs((upper_bounds[i]-lower_bounds[i])/lower_bounds[i])\n",
    "\n",
    "\n",
    "    data = {\"alpha\":alphas, \"z_alpha\":z_alphas, \"gap_%\":gaps, \"lb\":lower_bounds, \"up\":upper_bounds, \n",
    "            \"lb_time [s]\":lb_times, \"ub_time [s]\":ub_times, \"total_time [s]\": lb_times+ub_times}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for gap of 5% for CVaR_0.95\n",
    "seed = 1\n",
    "M = 5000\n",
    "N1 = 10\n",
    "N2 = 200000\n",
    "P = 5\n",
    "level_sig = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_1 = get_results_1(N1, N2, M, P, level_sig, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>z_alpha</th>\n",
       "      <th>gap_%</th>\n",
       "      <th>lb</th>\n",
       "      <th>up</th>\n",
       "      <th>lb_time [s]</th>\n",
       "      <th>ub_time [s]</th>\n",
       "      <th>total_time [s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-19.695784</td>\n",
       "      <td>0.334453</td>\n",
       "      <td>-19.719444</td>\n",
       "      <td>-19.653492</td>\n",
       "      <td>61.471275</td>\n",
       "      <td>30.525689</td>\n",
       "      <td>91.996964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-17.817592</td>\n",
       "      <td>0.332591</td>\n",
       "      <td>-17.836356</td>\n",
       "      <td>-17.777034</td>\n",
       "      <td>61.284125</td>\n",
       "      <td>31.190214</td>\n",
       "      <td>92.474339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-15.456353</td>\n",
       "      <td>0.390177</td>\n",
       "      <td>-15.479922</td>\n",
       "      <td>-15.419523</td>\n",
       "      <td>63.636208</td>\n",
       "      <td>30.397799</td>\n",
       "      <td>94.034007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-12.047175</td>\n",
       "      <td>0.541580</td>\n",
       "      <td>-12.079909</td>\n",
       "      <td>-12.014487</td>\n",
       "      <td>64.892966</td>\n",
       "      <td>30.751296</td>\n",
       "      <td>95.644261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-8.470665</td>\n",
       "      <td>1.160402</td>\n",
       "      <td>-8.534370</td>\n",
       "      <td>-8.435337</td>\n",
       "      <td>68.718516</td>\n",
       "      <td>30.614426</td>\n",
       "      <td>99.332942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-4.072606</td>\n",
       "      <td>4.399469</td>\n",
       "      <td>-4.218081</td>\n",
       "      <td>-4.032508</td>\n",
       "      <td>73.898993</td>\n",
       "      <td>30.507105</td>\n",
       "      <td>104.406098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha    z_alpha     gap_%         lb         up  lb_time [s]  ub_time [s]  \\\n",
       "0   0.01 -19.695784  0.334453 -19.719444 -19.653492    61.471275    30.525689   \n",
       "1   0.10 -17.817592  0.332591 -17.836356 -17.777034    61.284125    31.190214   \n",
       "2   0.25 -15.456353  0.390177 -15.479922 -15.419523    63.636208    30.397799   \n",
       "3   0.50 -12.047175  0.541580 -12.079909 -12.014487    64.892966    30.751296   \n",
       "4   0.75  -8.470665  1.160402  -8.534370  -8.435337    68.718516    30.614426   \n",
       "5   0.95  -4.072606  4.399469  -4.218081  -4.032508    73.898993    30.507105   \n",
       "\n",
       "   total_time [s]  \n",
       "0       91.996964  \n",
       "1       92.474339  \n",
       "2       94.034007  \n",
       "3       95.644261  \n",
       "4       99.332942  \n",
       "5      104.406098  "
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for gap of 1% for CVaR_0.95\n",
    "seed = 1\n",
    "M = 50000\n",
    "N1 = 10\n",
    "N2 = 5000000\n",
    "P = 5\n",
    "level_sig = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_2 = get_results_1(N1, N2, M, P, level_sig, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>z_alpha</th>\n",
       "      <th>gap_%</th>\n",
       "      <th>lb</th>\n",
       "      <th>up</th>\n",
       "      <th>lb_time [s]</th>\n",
       "      <th>ub_time [s]</th>\n",
       "      <th>total_time [s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-19.717734</td>\n",
       "      <td>0.246639</td>\n",
       "      <td>-19.758059</td>\n",
       "      <td>-19.709328</td>\n",
       "      <td>467.471984</td>\n",
       "      <td>546.457976</td>\n",
       "      <td>1013.929960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-17.835351</td>\n",
       "      <td>0.263678</td>\n",
       "      <td>-17.874493</td>\n",
       "      <td>-17.827362</td>\n",
       "      <td>547.807740</td>\n",
       "      <td>545.257071</td>\n",
       "      <td>1093.064811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-15.475425</td>\n",
       "      <td>0.295681</td>\n",
       "      <td>-15.513985</td>\n",
       "      <td>-15.468113</td>\n",
       "      <td>587.516338</td>\n",
       "      <td>538.508728</td>\n",
       "      <td>1126.025067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-12.066808</td>\n",
       "      <td>0.362239</td>\n",
       "      <td>-12.103738</td>\n",
       "      <td>-12.059894</td>\n",
       "      <td>599.989839</td>\n",
       "      <td>541.739476</td>\n",
       "      <td>1141.729314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-8.483084</td>\n",
       "      <td>0.541903</td>\n",
       "      <td>-8.522467</td>\n",
       "      <td>-8.476283</td>\n",
       "      <td>602.184598</td>\n",
       "      <td>540.493630</td>\n",
       "      <td>1142.678228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-4.089118</td>\n",
       "      <td>0.868112</td>\n",
       "      <td>-4.116780</td>\n",
       "      <td>-4.081042</td>\n",
       "      <td>883.977228</td>\n",
       "      <td>546.233051</td>\n",
       "      <td>1430.210279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha    z_alpha     gap_%         lb         up  lb_time [s]  ub_time [s]  \\\n",
       "0   0.01 -19.717734  0.246639 -19.758059 -19.709328   467.471984   546.457976   \n",
       "1   0.10 -17.835351  0.263678 -17.874493 -17.827362   547.807740   545.257071   \n",
       "2   0.25 -15.475425  0.295681 -15.513985 -15.468113   587.516338   538.508728   \n",
       "3   0.50 -12.066808  0.362239 -12.103738 -12.059894   599.989839   541.739476   \n",
       "4   0.75  -8.483084  0.541903  -8.522467  -8.476283   602.184598   540.493630   \n",
       "5   0.95  -4.089118  0.868112  -4.116780  -4.081042   883.977228   546.233051   \n",
       "\n",
       "   total_time [s]  \n",
       "0     1013.929960  \n",
       "1     1093.064811  \n",
       "2     1126.025067  \n",
       "3     1141.729314  \n",
       "4     1142.678228  \n",
       "5     1430.210279  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 CVaR en restricciones\n",
    "\n",
    "Llame $z_{\\alpha}$ el valor óptimo obtenido para cada problema anterior. Resuelva el problema estocástico de optimizar el valor esperado de retorno para el mismo problema anterior, pero bajo las restricciones adicionales de\n",
    "$CVaR_{\\alpha}(perdidas) ≤ z_{\\alpha} + 0,1 · max{|z_{\\alpha} |, 1}$ para $\\alpha \\in$ {0,25, 0,50, 0,75}.\n",
    "Busque $N_{1}$ , $N_{2}$, $M$ que resulten en un gap estocástico de menos del 2 %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_2(N1, N2, M, P, level_sig, df, seed):\n",
    "    \n",
    "\n",
    "    #samples for lower bound\n",
    "    c_x_1, c_y_1, d_1, w_1, v_1, W_1, V_1 = sampling_lb(N1, M, P, seed)\n",
    "\n",
    "    #samples for upper bound\n",
    "    c_x_2, c_y_2, d_2 = sampling_ub(N2, P, seed)\n",
    "\n",
    "    alphas = [0.25, 0.5, 0.75]\n",
    "    z_alphas = df[df[\"alpha\"].isin(alphas)][\"z_alpha\"].tolist()\n",
    "    gaps = np.zeros(len(alphas))\n",
    "    lower_bounds = np.zeros(len(alphas))\n",
    "    upper_bounds = np.zeros(len(alphas))\n",
    "    lb_times = np.zeros(len(alphas))\n",
    "    ub_times = np.zeros(len(alphas))\n",
    "\n",
    "    for i, alpha in enumerate(alphas):\n",
    "        ti_lb = time()\n",
    "        lower_bounds[i], x, t = computing_lb(c_x_1, c_y_1, d_1, w_1, v_1, W_1, V_1, alpha, level_sig, saa_type=\"cvar_rest\", z_alpha=z_alphas[i])\n",
    "        tf_lb = time()\n",
    "        lb_times[i] = tf_lb-ti_lb\n",
    "\n",
    "        ti_ub = time()\n",
    "        upper_bounds[i], z = computing_ub(c_x_2, c_y_2, d_2, x, t, alpha, level_sig, ssp_type=\"cvar_rest\")\n",
    "        tf_ub = time()\n",
    "        ub_times[i] = tf_ub-ti_ub \n",
    "        gaps[i] = 100*abs((upper_bounds[i]-lower_bounds[i])/lower_bounds[i])\n",
    "\n",
    "\n",
    "    data = {\"alpha\":alphas, \"z_alpha\":z_alphas, \"gap_%\":gaps, \"lb\":lower_bounds, \"up\":upper_bounds, \n",
    "            \"lb_time [s]\":lb_times, \"ub_time [s]\":ub_times, \"total_time [s]\": lb_times+ub_times}\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters using z_alpha from CVaR of 5% of gap\n",
    "seed = 1\n",
    "M = 1000\n",
    "N1 = 10\n",
    "N2 = 100000\n",
    "P = 5\n",
    "level_sig = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_1 = get_results_2(N1, N2, M, P, level_sig, df1_1, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>z_alpha</th>\n",
       "      <th>gap_%</th>\n",
       "      <th>lb</th>\n",
       "      <th>up</th>\n",
       "      <th>lb_time [s]</th>\n",
       "      <th>ub_time [s]</th>\n",
       "      <th>total_time [s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-15.456353</td>\n",
       "      <td>0.850301</td>\n",
       "      <td>-20.132230</td>\n",
       "      <td>-19.961045</td>\n",
       "      <td>15.325687</td>\n",
       "      <td>26.151750</td>\n",
       "      <td>41.477437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-12.047175</td>\n",
       "      <td>0.789035</td>\n",
       "      <td>-20.114079</td>\n",
       "      <td>-19.955372</td>\n",
       "      <td>16.764684</td>\n",
       "      <td>26.042437</td>\n",
       "      <td>42.807121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-8.470665</td>\n",
       "      <td>1.262854</td>\n",
       "      <td>-19.412823</td>\n",
       "      <td>-19.657979</td>\n",
       "      <td>15.647109</td>\n",
       "      <td>26.155910</td>\n",
       "      <td>41.803018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha    z_alpha     gap_%         lb         up  lb_time [s]  ub_time [s]  \\\n",
       "0   0.25 -15.456353  0.850301 -20.132230 -19.961045    15.325687    26.151750   \n",
       "1   0.50 -12.047175  0.789035 -20.114079 -19.955372    16.764684    26.042437   \n",
       "2   0.75  -8.470665  1.262854 -19.412823 -19.657979    15.647109    26.155910   \n",
       "\n",
       "   total_time [s]  \n",
       "0       41.477437  \n",
       "1       42.807121  \n",
       "2       41.803018  "
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters using z_alpha from CVaR of 1% of gap\n",
    "seed = 1\n",
    "M = 1000\n",
    "N1 = 10\n",
    "N2 = 100000\n",
    "P = 5\n",
    "level_sig = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>z_alpha</th>\n",
       "      <th>gap_%</th>\n",
       "      <th>lb</th>\n",
       "      <th>up</th>\n",
       "      <th>lb_time [s]</th>\n",
       "      <th>ub_time [s]</th>\n",
       "      <th>total_time [s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-15.475425</td>\n",
       "      <td>1.058886</td>\n",
       "      <td>-20.132230</td>\n",
       "      <td>-19.919052</td>\n",
       "      <td>10.997808</td>\n",
       "      <td>9.312509</td>\n",
       "      <td>20.310317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-12.066808</td>\n",
       "      <td>0.986778</td>\n",
       "      <td>-20.112661</td>\n",
       "      <td>-19.914194</td>\n",
       "      <td>11.993054</td>\n",
       "      <td>9.281674</td>\n",
       "      <td>21.274729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-8.483084</td>\n",
       "      <td>1.107213</td>\n",
       "      <td>-19.403561</td>\n",
       "      <td>-19.618400</td>\n",
       "      <td>11.423218</td>\n",
       "      <td>9.416892</td>\n",
       "      <td>20.840111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha    z_alpha     gap_%         lb         up  lb_time [s]  ub_time [s]  \\\n",
       "0   0.25 -15.475425  1.058886 -20.132230 -19.919052    10.997808     9.312509   \n",
       "1   0.50 -12.066808  0.986778 -20.112661 -19.914194    11.993054     9.281674   \n",
       "2   0.75  -8.483084  1.107213 -19.403561 -19.618400    11.423218     9.416892   \n",
       "\n",
       "   total_time [s]  \n",
       "0       20.310317  \n",
       "1       21.274729  \n",
       "2       20.840111  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_2 = get_results_2(N1, N2, M, P, level_sig, df1_2, seed)\n",
    "df2_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "\n",
    "### Parte 1\n",
    "En términos de tiempo resolver un SSP 1000 veces toma en promedio 10 $[ms]$ y un SAA con $M=1000$ es de 6 [s], esto significa que resolver un SAA toma 600 veces el tiempo de resolver un SSP de tamaño \"similar\".\n",
    "\n",
    "De los resultados se observa que es más fácil garantizar un gap menor para $\\alpha$ menor, esto puede deberse al hecho de que a menor $\\alpha$ crece $1-\\alpha$ y por tanto el área a integrar por la esperanza condicional es mayor, por lo que quedan más realizaciones en el lado donde se cálcula la esperanza lo que favorece la convergencia.  \n",
    "\n",
    "Notar que el tiempo de resolución es bastante similar independiente del $\\alpha$, por lo que el $\\alpha$ tiene influencia mínima en la resolución del SAA y el SSP, vale destacar que para $\\alpha$ pequeños se puede tener un tiempo de resolución inferior ya que  requieren de un menor tamaño de muestro para llegar a un gap aceptable.\n",
    "\n",
    "Los resultados encontrados muestran que si sequiere tener un gap aceptable (por ejemplo del 5 o 10%) basta con un tamaño de muestreo mediano, para el caso de $\\alpha=0.95$ (que es caso más difícil) toma menos de 2 minutos en alcanzar un gap del 5% y para un $\\alpha=0.75$ e inferior se llega a casi un 1% de gap en el mismo tiempo. Ahora bien, si se quiere llegar a un gap del 1% para $\\alpha=0.95$ el tamaño de muestreo requerido se dispara y el tiempo total de ejecución es 10 veces más. \n",
    "\n",
    "### Parte 2\n",
    "\n",
    "Notar que para el newsvendor con CVaR como restricción bajo un mismo tamaño de muestreo para todos los $\\alpha$ se obtiene un gap y tiempo de resolución bastante similar, por lo que no se observa el patrón de la primera pregunta, en donde un $\\alpha$ menor converge más rápido. Lo anterior puede deberse a que una cota inicial para el CVaR facilita la convergencia como también el hecho de que la función objetivo para este caso es una esperanza que no se encuentra condicionada, por lo que integra sobre todas las realizaciones (mismo argumento que en el segundo parráfo). Además, usando las soluciones óptimas obtenidas con los parámetros de muestreo que garantizaban un gap del 1% para el $CVaR_{0.95}$ se converge más rápido, lo que se debe al uso de una cota más apretada en la restricción del CVaR.\n",
    "\n",
    "Para la mayoría de los problemas de ingeniería obtener un resultado un epsilon mejor incrementando el costo computacional que requiere llegar a ese resultado genera un beneficio poco significativo, también se debe tener presente que los modelos son simplificaciones de la realidad y esas simplificaciones generan un gap entre el valor óptimo de resolver el problema de optimización de forma exacta y la realidad, siendo este gap mucho más significativo que el gap obtenido con una tolerancia aceptable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
